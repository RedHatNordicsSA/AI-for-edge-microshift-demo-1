{"cells":[{"cell_type":"markdown","source":"# Find faces in pictures\nWe start by loading an example picture using Python imaging library. Go ahead and **run the cell bellow** to see the image.","metadata":{"cell_id":"645ca9466167496b885d4a0e84fe3518","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"from PIL import Image, ImageDraw\nfrom IPython.display import display\n\n# The program we will be finding faces on the example below\npil_im = Image.open('two_people.jpg')\ndisplay(pil_im)","metadata":{"tags":[],"cell_id":"57e98f65c7ff4d8bb476145caaf0977a","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Learning from example\nNow we show the library two different faces ([Joe Biden](/biden.jpg), [Barack Obama](/obama.jpg)) and generate the encodings for them. Encoding is simply a low dimensional representation of a face that can be easily compared with other faces the library will recognize in the future.","metadata":{"tags":[],"cell_id":"c2e0b60a84944f07b7249e3319bc8988","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"import face_recognition\nimport numpy as np\nfrom PIL import Image, ImageDraw\nfrom IPython.display import display\n\n# This is an example of running face recognition on a single image\n# and drawing a box around each person that was identified.\n\n# Load a sample picture and learn how to recognize it.\nobama_image = face_recognition.load_image_file(\"obama.jpg\")\nobama_face_encoding = face_recognition.face_encodings(obama_image)[0]\n\n# Load a second sample picture and learn how to recognize it.\nbiden_image = face_recognition.load_image_file(\"biden.jpg\")\nbiden_face_encoding = face_recognition.face_encodings(biden_image)[0]\n\n# Create arrays of known face encodings and their names\nknown_face_encodings = [\n    obama_face_encoding,\n    biden_face_encoding\n]\nknown_face_names = [\n    \"Barack Obama\",\n    \"Joe Biden\"\n]\nprint('Learned encoding for', len(known_face_encodings), 'images.')","metadata":{"cell_id":"4816fbea06c34c55b19bc14de5e4e1ce","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Showtime\nFinally, we load the image we looked at in the first cell, find the faces in the image and compare them with the encodings the library generated in the previous step. We can see that library now correctly recognizes Barack and Joe in the input.","metadata":{"tags":[],"cell_id":"5c2f28043a06464aadc081b2aa4fb7e0","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# Load an image with an unknown face\nunknown_image = face_recognition.load_image_file(\"two_people.jpg\")\n\n# Find all the faces and face encodings in the unknown image\nface_locations = face_recognition.face_locations(unknown_image)\nface_encodings = face_recognition.face_encodings(unknown_image, face_locations)\n\n# Convert the image to a PIL-format image so that we can draw on top of it with the Pillow library\n# See http://pillow.readthedocs.io/ for more about PIL/Pillow\npil_image = Image.fromarray(unknown_image)\n# Create a Pillow ImageDraw Draw instance to draw with\ndraw = ImageDraw.Draw(pil_image)\n\n# Loop through each face found in the unknown image\nfor (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n    # See if the face is a match for the known face(s)\n    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n\n    name = \"Unknown\"\n\n    # Or instead, use the known face with the smallest distance to the new face\n    face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n    best_match_index = np.argmin(face_distances)\n    if matches[best_match_index]:\n        name = known_face_names[best_match_index]\n\n    # Draw a box around the face using the Pillow module\n    draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n\n    # Draw a label with a name below the face\n    text_width, text_height = draw.textsize(name)\n    draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n    draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n\n\n# Remove the drawing library from memory as per the Pillow docs\ndel draw\n\n# Display the resulting image\ndisplay(pil_image)","metadata":{"tags":[],"cell_id":"f4b534319d4543179c009b21a74769eb","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=4664c165-edc0-48c8-beb5-a255c2749fdb' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"},"deepnoteSessionId":"8b3c3451-4353-4ef0-acbf-97ffca907435","deepnote_notebook_id":"d322bc9ca81a40a698df95785139383c","deepnote_execution_queue":[]}}
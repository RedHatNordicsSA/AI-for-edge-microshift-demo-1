{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fdc6ae-2555-4b2a-a3f2-8671fbca530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336233ca-7aae-4468-a5a8-82bed695d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_mark_faces(frame, logger, cam_ip):\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=RATIO, fy=RATIO)\n",
    "    face_locations = face_recognition.face_locations(small_frame, 1, \"hog\")\n",
    "    names = []\n",
    "    face_encodings = face_recognition.face_encodings(small_frame, face_locations)\n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        name = \"Unknown\"\n",
    "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        if matches[best_match_index]:\n",
    "            name = known_face_names[best_match_index]\n",
    "        names.append(name)\n",
    "\n",
    "        logger.info(\"[cam %s] face_locations = %s, names = %s\", cam_ip, face_locations, names)\n",
    "\n",
    "        for (top, right, bottom, left), name in zip(face_locations, names):\n",
    "            add_name_box(frame, left, top, bottom, right, name)\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def add_name_box(frame, left, top, bottom, right, name):\n",
    "    inv_ratio = 1.0 / RATIO\n",
    "    top = int(top * inv_ratio)\n",
    "    right = int(right * inv_ratio)\n",
    "    bottom = int(bottom * inv_ratio)\n",
    "    left = int(left * inv_ratio)\n",
    "    cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "    cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a5a5b6-c5e2-4198-87c6-e08a52f2cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO, traverse directories and generate automatically\n",
    "ricky1_face_encoding = face_recognition.face_encodings(\n",
    "    face_recognition.load_image_file(\"/opt/app-root/src/AI-for-edge-microshift-demo/notebooks/faces/Ricardo Noriega/ricky1.jpg\"))[0]\n",
    "\n",
    "ajo1_face_encoding = face_recognition.face_encodings(\n",
    "    face_recognition.load_image_file(\"/opt/app-root/src/AI-for-edge-microshift-demo/notebooks/faces/Miguel Angel Ajo/ajo1.jpg\"))[0]\n",
    "\n",
    "rbohne_face_encoding = face_recognition.face_encodings(\n",
    "    face_recognition.load_image_file(\"/opt/app-root/src/AI-for-edge-microshift-demo/notebooks/faces/Robert Bohne/rbohne.jpg\"))[0]\n",
    "\n",
    "known_face_encodings = [\n",
    "        ricky1_face_encoding,\n",
    "        ajo1_face_encoding,\n",
    "        rbohne_face_encoding,\n",
    "        ]\n",
    "\n",
    "known_face_names = [\n",
    "        \"Ricardo Noriega\",\n",
    "        \"Miguel Angel Ajo\",\n",
    "        \"Robert Bohne\"\n",
    "    ]\n",
    "\n",
    "RATIO = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f8821-e094-43b8-a300-ab3563556ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
